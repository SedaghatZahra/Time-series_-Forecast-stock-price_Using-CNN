{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4XxGaqX9Yg3",
    "outputId": "3020d3a8-5cd7-4cb7-fb7d-091c236dec44"
   },
   "outputs": [],
   "source": [
    "# the name of the data file\n",
    "file_name = 'Dataset\\\\Data.xlsx'\n",
    "# the forecast size is the number of points that will be forecasted\n",
    "# That means How many days or hours or months you want forecast , if the data monthly and put in forecast size 15 then code will display forecast for 15 months  \n",
    "forecast_size = 15\n",
    "# the number of the category that the model will train on (open) hase number 1, (close) has number 4 .\n",
    "# That means forecast based which category you want .\n",
    "category = 3\n",
    "# the percentage of the data that will be used for training. the value of must be between 0.0, 1.0\n",
    "train_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the excel file\n",
    "df = pandas.read_excel(file_name)\n",
    "keys = [i for i in df]\n",
    "data = df.to_numpy()[1:]\n",
    "train_size = int(data.shape[0] * train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detection the type of input dataset to do the later prediction (yearly,monthly,weekly,daily,hourly)\n",
    "monthly, daily, hourly, weekly,yearly = 0, 0, 0, 0, 0\n",
    "aa = data[1][0]-data[0][0]\n",
    "if aa == 1:\n",
    "    yearly = 1\n",
    "    period = 1\n",
    "else:\n",
    "    aa = aa.value\n",
    "    if aa / 3600000000000 == 1:\n",
    "        hourly = 1\n",
    "        period = 24\n",
    "    elif aa / 3600000000000 == 24:\n",
    "        daily = 1\n",
    "        period = 30\n",
    "    elif aa / 3600000000000 == 24*7:    \n",
    "        weekly = 1\n",
    "        period = 1\n",
    "    else:\n",
    "        monthly = 1\n",
    "        period = 12\n",
    "        \n",
    "print('hourly : ',hourly) \n",
    "print('daily  : ',daily)\n",
    "print('weekly : ',weekly)\n",
    "print('monthly: ',monthly)\n",
    "print('yearly : ',yearly)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splite the dataset\n",
    "date = data[0,0]\n",
    "data = np.float32(data[:,category])\n",
    "data[np.isnan(data)] = 0\n",
    "data[data==0] = 2**-15\n",
    "normalize = 1\n",
    "for i in range(16):\n",
    "    if abs(np.max(data) - 2**i) < abs(np.max(data) - normalize):\n",
    "        normalize = 2**i\n",
    "\n",
    "data = data / normalize\n",
    "x = []\n",
    "y = []\n",
    "for i in range(data.shape[0]-period):        \n",
    "    x.append([data[i+j] for j in range(period)])\n",
    "    y.append([data[i+period]])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x_train = x[:train_size]\n",
    "y_train = y[:train_size]\n",
    "if True:\n",
    "    x.shape = (1,)+ x.shape\n",
    "    y.shape = (1,)+ y.shape\n",
    "    x_train.shape = (1,)+ x_train.shape\n",
    "    y_train.shape = (1,)+ y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat model\n",
    "tf.random.set_random_seed(0)    \n",
    "k = keras.backend\n",
    "def mape2(y_true, y_pred):\n",
    "    er_train = keras.losses.mape(y_true, y_pred)\n",
    "    er_test = keras.losses.mape(y_true[:,train_size:], y_pred[:,train_size:])\n",
    "    er = (k.mean(er_train, axis=-1, keepdims=True) + k.mean(er_test, axis=-1, keepdims=True)) * 0.5\n",
    "    return er\n",
    "\n",
    "file_name = 'Results\\\\A_CNN_Data.xlsx'\n",
    "# CNN\n",
    "model = keras.Sequential([\n",
    "keras.layers.InputLayer((None, x_train.shape[2])),\n",
    "keras.layers.Conv1D(128, 3, strides=1, padding='same', activation='elu'),\n",
    "keras.layers.Conv1D(128, 3, strides=1, padding='same', activation='elu'),\n",
    "keras.layers.Conv1D(128, 3, strides=1, padding='same', activation='elu'),\n",
    "keras.layers.Conv1D(128, 3, strides=1, padding='same', activation='elu'),\n",
    "keras.layers.Conv1D(1, 1, strides=1, padding='same')\n",
    "])\n",
    "model.compile('adam', 'mse', ['mape', mape2])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=1000, validation_data=(x, y), \n",
    "          callbacks=[keras.callbacks.EarlyStopping(\n",
    "                monitor='val_mape2', patience=4000,\n",
    "                mode='min', restore_best_weights=True) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the model and calculate the error and creating the output file\n",
    "mape = np.mean(np.abs(model.predict(x_train) - y_train) / np.abs(y_train)) * 100\n",
    "print('train mape: ' + str(mape) + '\\n')\n",
    "p = model.predict(x)\n",
    "if p.shape[0] == 1:\n",
    "    mape = np.mean(np.abs(p[:,train_size:] - y[:,train_size:]) / np.abs(y[:,train_size:])) * 100\n",
    "else:\n",
    "    mape = np.mean(np.abs(p[train_size:] - y[train_size:]) / np.abs(y[train_size:])) * 100\n",
    "\n",
    "print('test mape: ' + str(mape) + '\\n')\n",
    "\n",
    "o = x.copy()\n",
    "shape = o.shape[0]\n",
    "if shape == 1:\n",
    "    shape = o.shape[1]\n",
    "for i in range(shape, shape+forecast_size+1):\n",
    "    p = model.predict(o)\n",
    "    if o.shape[0] > 1:\n",
    "        ap = np.append(o[-1:,1:], p[-1:], axis=-1)\n",
    "    else:\n",
    "        ap = np.append(o[:,-1:,1:], p[:,-1:], axis=-1)\n",
    "    o = np.append(o, ap, axis=-2)\n",
    "\n",
    "if o.shape[0] == 1: o = o[0]\n",
    "oo = []\n",
    "pad = [[i] for i in data[:period-1]]\n",
    "for j in [pad, o]:\n",
    "    for i in j:\n",
    "        oo.append([date, i[-1]*normalize])\n",
    "        if hourly == 1:\n",
    "            date = date + pandas.offsets.DateOffset(hours=1)\n",
    "        elif daily == 1:\n",
    "            date = date + pandas.offsets.DateOffset(days=1)\n",
    "        elif monthly == 1:\n",
    "            date = date + pandas.offsets.DateOffset(months=1)\n",
    "        elif weekly == 1:\n",
    "            date = date + pandas.offsets.DateOffset(weeks=1)    \n",
    "        elif yearly == 1:\n",
    "            date = date + 1\n",
    "            \n",
    "\n",
    "df = pandas.DataFrame(oo)\n",
    "df.columns = ['date', keys[category]]\n",
    "pandas.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print('forecasted data:')\n",
    "print(df)\n",
    "df.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniplot(df1,df2,df1_col1,df1_col2,df2_col2,xlable,ylabel,legend1,legend2):\n",
    "    plt.figure(1, figsize=(14, 6))\n",
    "    plt.plot(df1[df1_col1],df1[df1_col2],'r--')\n",
    "    plt.plot(df2.iloc[:,0],df2[df2_col2],'b')\n",
    "    plt.xlabel(xlable)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend([legend1, legend2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib. pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_excel('Results\\\\A_CNN_Data.xlsx', parse_dates=True)\n",
    "df2 = pandas.read_excel('Dataset\\\\Data.xlsx', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniplot(df1,df2,'date','Low','Low','Date','Low','Predict','Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN .ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "BERT4",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
